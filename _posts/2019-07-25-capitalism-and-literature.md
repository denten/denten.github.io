---
layout: post
title: "A Friendly Response to Causal Literary Explanations"
categories:
- think.stack
published: false
---

A [recent essay](https://www.publicbooks.org/how-capitalism-changed-american-literature) in
*Public Books* by Dan Sinykin purports to answer the question of How Capitalism Changed
American Literature. It is an interesting question but the computational methods employed by
the author fall short of an answer. Experimental designs of the kind that builds "models"
comprised of correlations used to predict a binary category cannot in fact, produce an
explanatory answer. It is interesting to reflect briefly on why.

> Did conglomeration change the stories we told or how we told them?

The very form of this big question promises a causal explanation. Causal inference is a complex
and [fascinating topic](https://press.princeton.edu/titles/5458.html) on its own. Crucially,
causation and more so explanation are notoriously difficult to isolate from mere correlation.

Dan finds that novels in the category (A), published by Coffee House, Graywolf, Milkweed, and
Mercury House differ from those in category (B), published by Random House, in the words that
are indicative of each grouping. The non-profits can be best predicted by words such as "dust,"
"sweat," "colors," and "rhythm" and what he calls the "conglomerates" are best predicted by
"lawyer," "desk," "mood," and "suspicion" among others. So far, so good.

Why do these grouping differ? In asking this I am asking you to construct a plausible
explanation by which "non-profit" and "conglomerate" publishing worlds could produce
differences on the level of a text. For example, it could be the "conglomerates" work through
an agent and "non-profits" don't. Is this true? I don't know and didn't learn from the essay.
It could also be that those who choose to publish with a non-profit are a self-selected group
of wealthy male authors. The opposite could be the case also. Or that some of the smaller
presses specialize in particular audiences while the larger do not. Any number of such
confounding factors could explain the difference and tested empirically. But whatever the
explanation, it would rely on contextual information about the book market. This understanding
of the context cannot be reduced to a "model" used to isolate purely textual, predicative
features. None of them lead to an answer about change much less about the reasons, the how, of
capitalism and its effects. The method does not live up to its implied theories.

> I built this model to investigate whether nonprofits are, as they claim, more literary than
> conglomerates. The results allow me to extend recent computational studies into literariness
> and answer *yes*.

But wait a moment. We agreed to build a model that would narrowly identify most predicative
features in either category. Dan further groups the "conglomerate" terms into three topics (I
believe by hand): dispositions, bureaucracy, and law and order. The non-profit grouping he
leaves as is, even though it contains terms from very different semantic orders such as
"fingers," "colors," "dust," and "surface." The essay goes on to suggest that the topics in the
one and the lack of topics in the another indicate "literariness." Let's set aside the
difficulty of defining the literary. In this case, the decision to group one and not the other
was an arbitrary choice, a part of the imposed experimental design.  We therefore learn
something about the author's assumption about literariness, but not so much about the
differences in publishing houses. I will forego a discussion on why eye-balling the top 15
words (and not, let's say 150) is a poor substitute for formal analysis. Or why it's a bad idea
to cherry-pick words like "fiction."

If are are going to examine the impact of capitalism on literature formally, let's agree on our
definitions before setting up the experiment, and not after. We need a model and a theory. The
author would then need to convince us that his methods indeed capture his intuitions.

To be sure, I am certainly pleased that formal analysis is gaining traction in literary
studies. But before we get to the cutting edge, let's work on *Public Books* promises to become
an exciting venue for a conversation on the finer points of cultural analytics. But before we
approach the cutting edge, let's anchor the discussion in the foundations of statistical
reasoning. Machine learning makes for a good exploratory tool of the kind that stimulates
intuition. To make the next step, we need theoretical grounding and clarity in experiment
design.
